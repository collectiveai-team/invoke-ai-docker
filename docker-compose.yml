version: '3.8'
services:
    invoke-ai-core:
        image: ${CORE_IMAGE}
        container_name: invoke-ai
        build:
            args:
                - PYTHON_VERSION=${PYTHON_VERSION}
                - PIP_VERSION=${PIP_VERSION}
                - PYTORCH_VERSION=${PYTORCH_VERSION}
                - TORCHVISION_VERSION=${TORCHVISION_VERSION}
                - CUDA_VERSION=${CUDA_VERSION}
                - INVOKE_AI_VERSION=${INVOKE_AI_VERSION}

    invoke-ai-gpu:
        network_mode: host
        image: ${CORE_IMAGE}
        container_name: invoke-ai-gpu
        deploy:
            resources:
                reservations:
                    devices:
                        - capabilities: [ gpu ]
        shm_size: '16gb'
        env_file:
            - .env
        ports:
        - "9090:9090"
        volumes:
            - $PWD/outputs:/root/InvokeAI/outputs

    invoke-ai-cpu:
        network_mode: host
        image: ${CORE_IMAGE}
        container_name: invoke-ai-cpu
        shm_size: '16gb'
        env_file:
            - .env
        ports:
        - "9090:9090"
        volumes:
            - $PWD/outputs:/root/InvokeAI/outputs
